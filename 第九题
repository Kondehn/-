from sklearn.feature_extraction.text import CountVectorizer
import os
import numpy as np
from sklearn import svm
from sklearn import metrics
from sklearn.model_selection import train_test_split

def load_one_file(filename):
    x=""
    with open(filename,encoding='gb18030', errors='ignore') as f:
        for line in f:
            line = line.strip('\n')
            line = line.strip('\r')
            x+=line
    return x
    
def load_files_from_dir(rootdir):
    x=[]
    list = os.listdir(rootdir)
    for i in range(0,len(list)):
        path = os.path.join(rootdir,list[i])
        if os.path.isfile(path):
            v=load_one_file(path)
            x.append(v)
    return x
    
def load_all_files():
    ham=[]
    spam=[]
    for i in range(1,7):
        path="/Users/Raven/Desktop/mail/enron%d/ham/" % i
        print("Load %s" % path)
        ham+=load_files_from_dir(path)
        path="/Users/Raven/Desktop/mail/enron%d/spam/" % i
        print("Load %s" % path)
        spam+=load_files_from_dir(path)
    return ham,spam
    
def get_features_by_wordbag():
    ham,spam=load_all_files()
    x=ham+spam
    y=[0]*len(ham)+[1]*len(spam)
    vectorizer=CountVectorizer(decode_error='ignore',
                              strip_accents='ascii',
                              max_features=18000,
                              stop_words='english',
                              max_df=1.0,
                              min_df=1)
    print(vectorizer)
    x=vectorizer.fit_transform(x)
    x=x.toarray()
    return x,y
    
def do_svm_wordbag(x_train,x_test,ytrain,y_test):
    print("SVM and wordbag")
    clf = svm.SVC()
    clf.fit(x_train,y_train)
    y_pred=clf.predict(x_test)
    print(metrics.accuracy_score(y_test,y_pred))
    print(metrics.confusion_matrix(y_test,y_pred))
    
if __name__=="__main__":
    x,y=get_features_by_wordbag()
    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.4, random_state = 0)
    do_svm_wordbag(x_train, x_test, y_train, y_test)
